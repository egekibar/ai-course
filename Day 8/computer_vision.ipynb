{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "5eVVFxTLpVGb",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.335659Z",
     "start_time": "2024-07-31T15:06:15.333534Z"
    }
   },
   "source": "#pip install opencv-python",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HUvNtKu2pVGc",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.414559Z",
     "start_time": "2024-07-31T15:06:15.336569Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HjRuzl8_pVGd",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.557833Z",
     "start_time": "2024-07-31T15:06:15.415216Z"
    }
   },
   "source": [
    "input_1 = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Hello world\",input_1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.014] global loadsave.cpp:241 findDecoder imread_('input_1.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m input_1 \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_1.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHello world\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43minput_1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m cv2\u001B[38;5;241m.\u001B[39mwaitKey()\n\u001B[1;32m      4\u001B[0m cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bh72eu4CpVGd",
    "outputId": "499fda21-76e1-4972-cd7c-5d63d295464e",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.559584Z",
     "start_time": "2024-07-31T15:06:15.559501Z"
    }
   },
   "source": [
    "print ('Heiht of image', int(input_1.shape[0]),'pixels')\n",
    "print ('Width of image', int(input_1.shape[1]),'pixels')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HSGIkx0YpVGe",
    "outputId": "849843dd-8e5d-4e00-ed2c-f514bb0dc43d"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "checkBoard = np.zeros((9,9))\n",
    "checkBoard[0::2,1::2]=1\n",
    "checkBoard[1::2,0::2]=1\n",
    "print(checkBoard)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "54qCG1WkpVGf"
   },
   "source": [
    "import matplotlib.image as mpig"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b5HSW1r3pVGf",
    "outputId": "e69131f8-2a60-49de-8657-8de464a51ee2"
   },
   "source": [
    "plt.imshow(checkBoard,cmap=\"gray\",interpolation=\"nearest\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "sNP5_ZETpVGf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f93637b1-f5c8-46a3-cfb9-15ec12e19d05"
   },
   "source": [
    "from skimage import data\n",
    "image_of_a_bush = data.lfw_subset()\n",
    "image_of_a_bush = image_of_a_bush[0,:,:]\n",
    "print(image_of_a_bush)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_ZO6hIuvpVGg",
    "outputId": "be06ed26-75ca-4c83-8a82-e8f6d1a3e684"
   },
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image_of_a_bush,cmap=\"gray\",interpolation=\"nearest\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "66WXO4G2pVGg",
    "outputId": "004d5e55-f2ec-4764-997f-a1df952d8ffc"
   },
   "source": [
    "image = data.astronaut()\n",
    "plt.imshow(image)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nx-jMk6EpVGh"
   },
   "source": [
    "image = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.waitKey()\n",
    "\n",
    "gray_image= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Grayscale\",gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CxUEaEZupVGh"
   },
   "source": [
    "img = cv2.imread(\"input_1.jpg\",0)\n",
    "cv2.imshow(\"Grayscale\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U5DE2iqFpVGh",
    "outputId": "db60374b-6b9a-4575-805d-61cea13889da"
   },
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "B,G,R = image[0,0]\n",
    "B,G,R = image[10,50]\n",
    "print(B,G,R)\n",
    "print(image.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jGJDcBkupVGi",
    "outputId": "9452ee4d-f985-4a77-ccad-90ae7e67718f"
   },
   "source": [
    "gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "print(gray_img.shape)\n",
    "print(gray_img[10,50])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1lWvnhvzpVGi",
    "outputId": "0b356b3b-0989-49e9-c627-d86c5258712d"
   },
   "source": [
    "gray_img[0,0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "spdthWb0pVGi",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.589141Z",
     "start_time": "2024-07-31T15:06:15.576317Z"
    }
   },
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "hsv_image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV image\",hsv_image[:,:,:])\n",
    "cv2.imshow(\"Hue channel\",hsv_image[:,:,0])\n",
    "cv2.imshow(\"Saturation channel\",hsv_image[:,:,1])\n",
    "cv2.imshow(\"Calue channel\",hsv_image[:,:,2])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.175] global loadsave.cpp:241 findDecoder imread_('input.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m hsv_image \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcvtColor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCOLOR_BGR2HSV\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHSV image\u001B[39m\u001B[38;5;124m\"\u001B[39m,hsv_image[:,:,:])\n\u001B[1;32m      5\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHue channel\u001B[39m\u001B[38;5;124m\"\u001B[39m,hsv_image[:,:,\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EJUOMHEOpVGi",
    "outputId": "52e1736b-f406-4cde-f32c-be5c8f07c579",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.637370Z",
     "start_time": "2024-07-31T15:06:15.625486Z"
    }
   },
   "source": [
    "image = cv2.imread(\"input_1.jpg\")\n",
    "B,G,R =cv2.split(image)\n",
    "print(B.shape)\n",
    "cv2.imshow(\"Red\",R)\n",
    "cv2.imshow(\"Green\",G)\n",
    "cv2.imshow(\"Blue\",B)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "merged = cv2.merge([B,G,R])\n",
    "cv2.imshow(\"Merged\",merged)\n",
    "merged= cv2.merge([B+100,G,R+100])\n",
    "cv2.imshow(\"Merged with Blue Amplified\",merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.224] global loadsave.cpp:241 findDecoder imread_('input_1.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_1.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m B,G,R \u001B[38;5;241m=\u001B[39mcv2\u001B[38;5;241m.\u001B[39msplit(image)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(B\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      4\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRed\u001B[39m\u001B[38;5;124m\"\u001B[39m,R)\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1XcQvJ1DpVGi",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.819165Z",
     "start_time": "2024-07-31T15:06:15.808363Z"
    }
   },
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "quareter_height,quareter_width = height/4,width/4\n",
    "\n",
    "T = np.float32([[1,0,quareter_width],[0,1,quareter_height]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image,T,(width,height))\n",
    "cv2.imshow('Translation',img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.407] global loadsave.cpp:241 findDecoder imread_('input.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m height,width \u001B[38;5;241m=\u001B[39m \u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m      5\u001B[0m quareter_height,quareter_width \u001B[38;5;241m=\u001B[39m height\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m4\u001B[39m,width\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m4\u001B[39m\n\u001B[1;32m      7\u001B[0m T \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat32([[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m0\u001B[39m,quareter_width],[\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m,quareter_height]])\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_JtZgEoDpVGj",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.888673Z",
     "start_time": "2024-07-31T15:06:15.878481Z"
    }
   },
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2),45,.5)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "\n",
    "cv2.imshow('Rotated Image',rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.477] global loadsave.cpp:241 findDecoder imread_('input.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m height,width \u001B[38;5;241m=\u001B[39m \u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m      5\u001B[0m rotation_matrix \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mgetRotationMatrix2D((width\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m,height\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m),\u001B[38;5;241m45\u001B[39m,\u001B[38;5;241m.5\u001B[39m)\n\u001B[1;32m      7\u001B[0m rotated_image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mwarpAffine(image,rotation_matrix,(width,height))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wkc8sfQopVGj",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:15.926169Z",
     "start_time": "2024-07-31T15:06:15.914142Z"
    }
   },
   "source": [
    "image = cv2.imread('input_1.jpg',0)\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "sobel_x = cv2.Sobel(image,cv2.CV_64F,0,1,ksize = 5)\n",
    "sobel_y = cv2.Sobel(image,cv2.CV_64F,1,0,ksize = 5)\n",
    "\n",
    "cv2.imshow('Rotated Image',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X',sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y',sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('sobel_OR',sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "cv2.imshow('Laplacian',laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image,50,120)\n",
    "cv2.imshow('Canny',canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.514] global loadsave.cpp:241 findDecoder imread_('input_1.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_1.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m height,width \u001B[38;5;241m=\u001B[39m \u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m      5\u001B[0m sobel_x \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mSobel(image,cv2\u001B[38;5;241m.\u001B[39mCV_64F,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m,ksize \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m      6\u001B[0m sobel_y \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mSobel(image,cv2\u001B[38;5;241m.\u001B[39mCV_64F,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m0\u001B[39m,ksize \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0-IbFQdKpVGj",
    "outputId": "00b5bd8f-c326-4c53-8317-59a3ebae7b45",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:20.966741Z",
     "start_time": "2024-07-31T15:06:15.980609Z"
    }
   },
   "source": [
    "def sketch(image):\n",
    "    img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "    canny_edges = cv2.Canny(img_gray_blur,10,70)\n",
    "    ret,mask = cv2.threshold(canny_edges,250,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow('Our live Sketcher',sketch(frame))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 18:06:16.243 python[11121:151530] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MFVCDZQfpVGk",
    "ExecuteTime": {
     "end_time": "2024-07-31T15:06:20.980614Z",
     "start_time": "2024-07-31T15:06:20.968227Z"
    }
   },
   "source": [
    "image = cv2.imread(\"WaldoBeach.jpg\")\n",
    "\n",
    "cv2.imshow(\"Where is Waldo\",image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "template = cv2.imread(\"waldo.jpg\",0)\n",
    "\n",
    "result = cv2.matchTemplate(gray,template,cv2.TM_CCOEFF)\n",
    "minVal,maxVal,minLoc,maxLoc = cv2.minMaxLoc(result)\n",
    "\n",
    "top_left = maxLoc\n",
    "bottom_right =(top_left[0] + 50, top_left[1]+50)\n",
    "cv2.rectangle(image,top_left,bottom_right,(0,0,255),5)\n",
    "\n",
    "cv2.imshow(\"Where is Waldo\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@5.567] global loadsave.cpp:241 findDecoder imread_('WaldoBeach.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWaldoBeach.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWhere is Waldo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m cv2\u001B[38;5;241m.\u001B[39mwaitKey(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      5\u001B[0m gray \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(image,cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2GRAY)\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i8kjuqaXpVGk",
    "outputId": "351bfa5e-b9f3-4665-a999-cebc0d240095"
   },
   "source": [
    "plt.imshow(template)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B-S7xojNpVGk"
   },
   "source": [
    "import imutils\n",
    "image = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "\n",
    "flipped = cv2.flip(image,0)\n",
    "cv2.imshow(\"Vertical Flip\",flipped)\n",
    "\n",
    "flipped = cv2.flip(image,1)\n",
    "cv2.imshow(\"Horizontal Flip\",flipped)\n",
    "\n",
    "flipped = cv2.flip(image,-1)\n",
    "cv2.imshow(\"Bot Flip\",flipped)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4AJo20JmpVGk"
   },
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret,frame= cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Demo\",frame)\n",
    "    else:\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qeOMBFaJpVGk"
   },
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame= cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Bendeniz\",frame)\n",
    "    else:\n",
    "        break\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WQe_kvw2pVGk"
   },
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OGc9tGiApVGl"
   },
   "source": [
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1pVos3M0pVGl"
   },
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z8lAUuLDpVGl"
   },
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "\n",
    "    thresh = cv2.threshold(diff,20,255,cv2.THRESH_BINARY)[1]\n",
    "    final = cv2.dilate(thresh,None,iterations=2)\n",
    "\n",
    "    masked = cv2.bitwise_and(frame1,frame1,mask=thresh)\n",
    "    white_pixels = np.sum(thresh) /255\n",
    "\n",
    "    rows,cols = thresh.shape\n",
    "    total= rows*cols\n",
    "    if white_pixels > 0.01*total:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame1,\"Movement Detected - Hareket Var\",(10,50),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"Motion\",frame1)\n",
    "    frame1=frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27 or key == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zlPQreyTpVGl",
    "outputId": "bfa57b7f-f2ff-425f-9be4-4dddf72228a9"
   },
   "source": [
    "image = cv2.imread(\"bunchofshapes.jpg\")\n",
    "cv2.imshow(\"Input Image\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edged = cv2.Canny(gray,30,200)\n",
    "cv2.imshow(\"Canny Edges\",edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "contours,hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow(\"Canny Edges After Contouring\",edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "cv2.drawContours(image,contours,-1,(0,255,0),thickness=2)\n",
    "\n",
    "cv2.imshow(\"Contours\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZTMU12WMpVGl",
    "outputId": "e7caba2c-5ac2-4ce7-8b8e-1ebf8154427f"
   },
   "source": [
    "plt.imshow(cv2.imread(\"bunchofshapes.jpg\",0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dtlsFOWFpVGm"
   },
   "source": [
    "image = cv2.imread('soduku.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "# Grayscale and Canny Edges extracted\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n",
    "\n",
    "# Run HoughLines using a rho accuracy of 1 pixel\n",
    "# theta accuracy of np.pi / 180 which is 1 degree\n",
    "# Our line threshold is set to 240 (number of points on line)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 240)\n",
    "\n",
    "# We iterate through each line and convert it to the format\n",
    "# required by cv2.lines (i.e. requiring end points)\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NB2hvPeNpVGm"
   },
   "source": [
    "image = cv2.imread('opencv.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 20)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    "\n",
    "cv2.imshow('detected circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WpSJmpxApVGm"
   },
   "source": [
    "# Read image\n",
    "image = cv2.imread(\"Sunflowers.jpg\")\n",
    "\n",
    "# Set up the detector with default par ameters.\n",
    "detector =cv2.SimpleBlobDetector_create()\n",
    "\n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "\n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PzBZINgvpVGn"
   },
   "source": [
    "# Read image\n",
    "image = cv2.imread(\"Sunflowers.jpg\")\n",
    "\n",
    "# Set up the detector with default par ameters.\n",
    "detector =cv2.SimpleBlobDetector_create()\n",
    "\n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "\n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "660ZBSGQpVGn",
    "outputId": "589b1696-9fa1-46ad-cb49-1daf4e197e62"
   },
   "source": [
    "\n",
    "# classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "image = cv2.imread('myself.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Our classifier returns the ROI of the detected face as a tuple\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rtomYqnxpVGn",
    "outputId": "a348ce99-6ff7-48ba-efdb-9822214945e7"
   },
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('myself.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No Face Found\")\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bgvwxQDfpVGn",
    "outputId": "112623a4-b6ef-4a7c-cda0-83b539582d8f"
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "def face_detector(img, size=0.5):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img\n",
    "    for (x,y,w,h) in faces:\n",
    "        x = x - 50\n",
    "        w = w + 50\n",
    "        y = y - 50\n",
    "        h = h + 50\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        sleep(.05)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n",
    "    img = cv2.flip(img,1)\n",
    "    return img\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Our Face Extractor', face_detector(frame))\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1711573338458,
     "user": {
      "displayName": "Meltem UÃ§ar",
      "userId": "06415093256480859049"
     },
     "user_tz": 360
    },
    "id": "wMqW0ro-pVGn"
   },
   "source": "#pip install opencv-contrib-python",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MQZYruJrpVGo",
    "outputId": "dc80359a-0731-44c6-868f-66fd98fd1554"
   },
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h,x:x+w]\n",
    "    return cropped_face\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        file_name_path = './faces/user/' + str(count) +'.jpg'\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow(\"Face Cropper\",face)\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13 or count ==100:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Collecting Samples Complete')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "avTpmEk0pVGo",
    "outputId": "c04e2241-fcd6-48a2-b495-51c239a94b1c"
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "\n",
    "data_path = './faces/user/'\n",
    "onlyfiles =[f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "Training_Data,Labels = [],[]\n",
    "\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images,dtype = np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "Labels = np.asarray(Labels,dtype = np.int32)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data),np.asarray(Labels))\n",
    "print(\"Model Trained Succesfully\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j6QTvwjIpVGo",
    "outputId": "34c747a7-2dd3-4d4d-ddc7-3b70bc24249f"
   },
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_extractor(img, size = 0.5):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return img,[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    image,face = face_extractor(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        results = model.predict(face)\n",
    "        if results[1]<500:\n",
    "            confidence = int(100 * (1-(results[1])/400))\n",
    "            display_string = str(confidence) + '% sure this guy is myself'\n",
    "        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX,1,(255,120,150),2)\n",
    "        if confidence > 75:\n",
    "            cv2.putText(image,\"Unlocked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow(\"Face Recognition\",image)\n",
    "        else:\n",
    "            cv2.putText(image,\"Locked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow(\"Face Recognition\",image)\n",
    "    except:\n",
    "        cv2.putText(image,\"No Face Found\" ,(220,120),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,\"Locked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.imshow(\"Face Recognition\",image)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        cap.release()\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
